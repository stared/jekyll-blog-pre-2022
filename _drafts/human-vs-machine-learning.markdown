---
layout: "post"
title: "Human vs Machine Learning"
date: "2017-12-26 12:30"
---

When I give an introduction to machine learning, I often start with the classic Iris dataset, printed on paper, and ask participants to draw division lines. Some people draw straight lines, while others  

[picture?]

While each particular machine learning algorithm comes with its own artifacts and limitations, some issues are much broader.

If fact, there are limitations of any learning process, machine or human alike.

## What is overfitting?


Overfitting is a problem when



* [Machine Learning Crash Course: Part 4 - The Bias-Variance Dilemma](https://ml.berkeley.edu/blog/2017/07/13/tutorial-4/) by Daniel Geng and Shannon Shih
* https://www.analyticsvidhya.com/blog/2014/10/introduction-k-neighbours-algorithm-clustering/ (maybe)
* http://christopherroach.com/articles/statistics-for-hackers/ (maybe)

For pathological examples of overfitting (which passed though per review of questionable quality):

* [Will women outrun men in ultra-marathon road races from 50 km to 1,000 km?](https://springerplus.springeropen.com/articles/10.1186/2193-1801-3-97) by (censored out of mercy)

Below,



(And in fact I did, in my Dreams, drugs & ConvNet talk.)

* too complex model,
* too high weights,
* too much memorization,
* extrapolation from too sparse data.

I will discussed both "active" cases, and ones frozen in the culture.

## Examples of overfitting

### Exams

You are a student learning for a difficult exam. Would you rather:

* revise note, re-read textb
* study exam questions.


In the worst case, if you memorize answers (question 1-A, 2-C, 3-A, 4-D, ...) it will works extremely well for the same exam set, but your accuracy will drop to guess-by chance level for a different question set (or even: a different order of answers).


### Memorization




I medical

To a point that I made a bet with a friend, on the lethal dose of potassium ions (a single does, orally). Her guess was closer to a recommended daily intake.  


* wetland biology camp
* potassium lethal does bet ()
* medicine in general

### Gender discrimination

One of hallmarks of overfitting are two high weights given to a certain trait. To fight it, we use regularization. Depending on your statistical philosophy, it is a penalty, or a Bayesian prior.



* [Are women paid less than men for the same work?](https://www.economist.com/blogs/graphicdetail/2017/08/daily-chart) - The Economist

### Nipples

In Western culture nudity is associated with sexuality.

What is more interesting from machine learning perspective is what do we consider nudity.
A woman exposing only a slightly part of her nipple is considered nude, while one showing her breasts (except for nipples) is considered dressed.



Sure, it may me benef

* [Genderless Nipples exposes Instagramâ€™s double standard on nudity](http://www.theverge.com/2016/12/6/13852900/genderless-nipples-instagram-censorship-policy)
* [Brestfeeding cartoon](http://beta.latimes.com/opinion/topoftheticket/la-na-tt-breastfeeding-moms-20120705-story.html) by David Horsey

### Racism




* [How to make a racist AI without really trying](https://blog.conceptnet.io/2017/07/13/how-to-make-a-racist-ai-without-really-trying/) by Rob Speer



### Superstitions

Most cultures and religions believe in some supersitions.
Yet




### Conspiracy theories



Usually they don't take account for coincidences (i.e. noise) - every single event has some meaning and need to be fitted into the narrative.


### Tricks and hacks



## When it is not a problem

### When overfitting is acceptable

Overfitting can be good, or acceptable, in certain instances.

The prime example is compression - when we don't need our results to generalize.

[Mnemonic](https://en.wikipedia.org/wiki/Mnemonic), or memory techniques, can help learning languages, formuleae, phone numbers, etc.
They can work by compressing, creating redundancy, or transforming problems into ones that are easier to memorize.


### When underfitting is desirable

* insuarrances

##



## TODO, etc

### To mention

* Occam's razor
* porn in general, sweets, etc
* logical fallacies
* [king - man + woman is queen; but why?](http://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html)
* [Dating for nerds (part 2): gender differences](http://p.migdal.pl/2017/09/30/dating-for-nerds-gender-differences.html)
* https://www.reddit.com/r/MachineLearning/comments/4xr6bn/overfitting_and_human_brain/
* adversarial examples, https://blog.kjamistan.com/adversarial-learning-for-good-my-talk-at-34c3-on-deep-learning-blindspots/
* https://xkcd.com/1725/
* metaphors we live be
* maybe also: whales, mammals
* [Two heads are better than one. How about more?](https://egtheory.wordpress.com/2014/01/30/two-heads-are-better-than-one-how-about-more/)
* Knowledge, experience, overfitting
  * https://twitter.com/essiryy/status/634741367864954880
  * https://imgur.com/gallery/a6feg5X (with many)
  * http://www.myconfinedspace.com/2015/10/05/information-vs-knowledge-vs-conspiracy-theory/
* maybe to read https://www.reddit.com/r/MachineLearning/comments/7nt2sw/d_null_space_of_a_statistical_classifier/

neuroinspirations:

* https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/
* http://yosinski.com/deepvis
* https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures
* https://github.com/mlajtos/moniel and discussions there: https://github.com/mlajtos/moniel/issues/13

Confusion matrix:
* https://ml4a.github.io/demos/confusion_cifar_convnet/

###
